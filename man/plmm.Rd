% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plmm.R
\name{plmm}
\alias{plmm}
\title{Fit a linear mixed model with non-convex regularization}
\usage{
plmm(
  X,
  y,
  K,
  k = NULL,
  eta_star,
  penalty = c("MCP", "SCAD", "lasso"),
  gamma,
  alpha = 1,
  lambda.min,
  nlambda = 100,
  lambda,
  eps = 1e-04,
  max.iter = 10000,
  convex = TRUE,
  dfmax = p + 1,
  warn = TRUE,
  penalty.factor = rep(1, ncol(X)),
  init = rep(0, ncol(X)),
  returnX = TRUE
)
}
\arguments{
\item{X}{Design matrix. May include clinical covariates and other non-SNP data.}

\item{y}{Continuous outcome vector.}

\item{K}{Similarity matrix used to rotate the data. This should either be a known matrix that reflects the covariance of y, or an estimate (Default is \eqn{\frac{1}{p}(XX^T)}).}

\item{k}{An integer between 1 and \code{nrow(K)} indicating the number of singular values requested \emph{if} package \code{RSpectra} is installed. Defaults to NULL.}

\item{eta_star}{Optional argument to input a specific eta term rather than estimate it from the data. If K is a known covariance matrix that is full rank, this should be 1.}

\item{penalty}{The penalty to be applied to the model. Either "MCP" (the default), "SCAD", or "lasso".}

\item{gamma}{The tuning parameter of the MCP/SCAD penalty (see details). Default is 3 for MCP and 3.7 for SCAD.}

\item{alpha}{Tuning parameter for the Mnet estimator which controls the relative contributions from the MCP/SCAD penalty and the ridge, or L2 penalty. alpha=1 is equivalent to MCP/SCAD penalty, while alpha=0 would be equivalent to ridge regression. However, alpha=0 is not supported; alpha may be arbitrarily small, but not exactly 0.}

\item{lambda.min}{The smallest value for lambda, as a fraction of lambda.max. Default is .001 if the number of observations is larger than the number of covariates and .05 otherwise.}

\item{nlambda}{Length of the sequence of lambda. Default is 100.}

\item{lambda}{A user-specified sequence of lambda values. By default, a sequence of values of length nlambda is computed, equally spaced on the log scale.}

\item{eps}{Convergence threshold. The algorithm iterates until the RMSD for the change in linear predictors for each coefficient is less than eps. Default is \code{1e-4}.}

\item{max.iter}{Maximum number of iterations (total across entire path). Default is 10000.}

\item{convex}{Calculate index for which objective function ceases to be locally convex? Default is TRUE.}

\item{dfmax}{Upper bound for the number of nonzero coefficients. Default is no upper bound. However, for large data sets, computational burden may be heavy for models with a large number of nonzero coefficients.}

\item{warn}{Return warning messages for failures to converge and model saturation? Default is TRUE.}

\item{penalty.factor}{A multiplicative factor for the penalty applied to each coefficient. If supplied, penalty.factor must be a numeric vector of length equal to the number of columns of X. The purpose of penalty.factor is to apply differential penalization if some coefficients are thought to be more likely than others to be in the model. In particular, penalty.factor can be 0, in which case the coefficient is always in the model without shrinkage.}

\item{init}{Initial values for coefficients. Default is 0 for all columns of X.}

\item{returnX}{Return the standardized design matrix along with the fit? By default, this option is turned on if X is under 100 MB, but turned off for larger matrices to preserve memory.}
}
\value{
A list including the estimated coeficients on the original scale, as well as other model fitting details
}
\description{
This function allows you to fit a linear mixed model via non-convex penalized maximum likelihood.
}
\examples{
fit <- plmm(X = admix$X[,1:10], y = admix$y, K = relatedness_mat(admix$X))
summary(fit)
short_summary <- summary(fit)
}
