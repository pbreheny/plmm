<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="penalizedLMM">
<title>Getting started with penalizedLMM • penalizedLMM</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Getting started with penalizedLMM">
<meta property="og:description" content="penalizedLMM">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-dark"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">penalizedLMM</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/getting_started.html">Getting started with penalizedLMM</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Getting started with penalizedLMM</h1>
                        <h4 data-toc-skip class="author">Tabitha
Peter</h4>
            
            <h4 data-toc-skip class="date">2022-11-09</h4>
      
      
      <div class="d-none name"><code>getting_started.Rmd</code></div>
    </div>

    
    
<p><strong>NOTE</strong>: This vignette is under development – not all
of the examples here are fully worked through. In fact, as of this
writing, most of them are not working yet. My work here is an example of
<a href="https://notes.andymatuschak.org/About_these_notes?stackedNotes=z21cgR9K3UcQ5a7yPsj2RUim3oM2TzdBByZu" class="external-link">working
with the garage door open</a>.</p>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><code>penalizedLMM</code> is an <code>R</code> package created for
the purpose of fitting penalized regression models to high dimensional
data, particularly that in which the observations are not independent.
This kind of data arises often in the context of genetics (<em>e.g.</em>
GWAS dealing with population structure), and this will be the motivation
for the examples presented here.</p>
<p>At this time, the package is designed for linear regression only –
that is, we are considering only continuous (numeric) outcomes. In the
future, I would like to extend this package to handle logistic
regression (to handle dichotomous outcomes).</p>
<p>Since we are focused on penalized regression in this package,
<code>penalizedLMM</code> offers 3 choices of penalty: the minimax
concave (MCP), the smoothly clipped absolute deviation (SCAD), and the
least absolute shrinkage and selection operator (LASSO). Much of the
work in this package is built on the concepts/techniques provided in the
<code>ncvreg</code> package, whose author is <a href="https://myweb.uiowa.edu/pbreheny/" class="external-link">my thesis advisor</a>.</p>
<p><code>penalizedLMM</code> currently includes two example data
sets:</p>
<ul>
<li><p><code>admix</code> is a small data set (197 observations, 100
SNPs) that describes individuals of different racial backgrounds. The
outcome of <code>admix</code> is simulated to include population
structure effects (<em>i.e.</em> race/ethnicity have an impact on the
SNP associations).</p></li>
<li><p><code>cad_lite</code> (acronym for <strong>c</strong>oronary
<strong>a</strong>rtery <strong>d</strong>isease) is a lower mid-sized
data set (1401 observations, 4217 SNPs) with several health outcomes as
well as age and sex information. This data set is a subset of a much
larger data set (the original data has over 800K SNPs). For for
information on this data set, refer to the <a href="https://pubmed.ncbi.nlm.nih.gov/21239051/" class="external-link">original
publication</a>.</p></li>
<li><p><code>cad</code> (acronym for <strong>c</strong>oronary
<strong>a</strong>rtery <strong>d</strong>isease) is an upper mid-sized
data set (1401 observations, 42117 SNPs) with several health outcomes as
well as age and sex information. This data set is a larger subset the
same data used as the reference for <code>cad_lite</code>.</p></li>
</ul>
<p>In this overview, I will provide a demo of the main functions in
<code>penalizedLMM</code> using both of these data sets.</p>
</div>
<div class="section level2">
<h2 id="basic-model-fitting">Basic model fitting<a class="anchor" aria-label="anchor" href="#basic-model-fitting"></a>
</h2>
<p>The <code>admix</code> data is already formatted to have an <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span>, so I can jump right in with a call to
<code>plmm</code>:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">admix_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plmm.html">plmm</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">admix</span><span class="op">$</span><span class="va">X</span>, y <span class="op">=</span> <span class="va">admix</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">admix_fit</span>, lambda <span class="op">=</span> <span class="va">admix_fit</span><span class="op">$</span><span class="va">lambda</span><span class="op">[</span><span class="fl">95</span><span class="op">]</span><span class="op">)</span>
<span class="co"># MCP-penalized regression model with n=197, p=101 at lambda=0.00048</span>
<span class="co"># -------------------------------------------------</span>
<span class="co"># The model converged </span>
<span class="co"># -------------------------------------------------</span>
<span class="co"># # of non-zero coefficients:  98 </span>
<span class="co"># Constant features (features without variation):  Snp8 Snp14 </span>
<span class="co"># -------------------------------------------------</span></code></pre></div>
<p>The <code>cad_lite</code> data is in the bed/bim/fam format, so I
need to do some preprocessing first:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">cad_lite</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/process_plink.html">process_plink</a></span><span class="op">(</span>prefix <span class="op">=</span> <span class="st">"cad"</span>,
                          dataDir <span class="op">=</span> <span class="fu"><a href="../reference/plink_example.html">plink_example</a></span><span class="op">(</span>path<span class="op">=</span><span class="st">"cad.fam"</span>, parent<span class="op">=</span><span class="cn">T</span><span class="op">)</span><span class="op">)</span>
<span class="co"># </span>
<span class="co"># Preprocessing cad data:</span>
<span class="co"># </span>
<span class="co"># Removing  1346 SNPs that are monomorphic or outside of chromosomes 1-22.</span>
<span class="co"># </span>
<span class="co"># There are 34140 SNPs with missing data that we will attempt to impute.</span>
<span class="co"># SNPs tagged by a single SNP: 15366</span>
<span class="co"># SNPs tagged by multiple tag haplotypes (saturated model): 26817</span>
<span class="co"># </span>
<span class="co"># There are 15011 SNPs with missing data after imputation.</span>
<span class="co"># </span>
<span class="co"># Of these SNPs, 66 have call rates &lt;= 50% and will be removed.</span>
<span class="co"># </span>
<span class="co"># There are 14945 SNPs that still have missing data which will be imputed with the HWE expected value.</span>
<span class="co"># </span>
<span class="co"># Preprocessing cad data DONE!</span>
<span class="co">#  </span>
<span class="co"># Subjects: 1401 </span>
<span class="co"># SNPs: 42117 </span>
<span class="co"># Missing values: 0</span>
<span class="co"># NB: there is a 'quiet' option in process_plink() that will silence the printed messages</span>

<span class="va">cad_clinical</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html" class="external-link">read.csv</a></span><span class="op">(</span><span class="fu"><a href="../reference/plink_example.html">plink_example</a></span><span class="op">(</span>path<span class="op">=</span><span class="st">"cad_clinical.csv"</span><span class="op">)</span><span class="op">)</span>

<span class="co"># for the sake of illustration, I use a simple mean imputation for the outcome </span>
<span class="va">cad_clinical</span><span class="op">$</span><span class="va">hdl_impute</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">cad_clinical</span><span class="op">$</span><span class="va">hdl</span><span class="op">)</span>,
                                       <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">cad_clinical</span><span class="op">$</span><span class="va">hdl</span>, na.rm <span class="op">=</span> <span class="cn">T</span><span class="op">)</span>,
                                       <span class="va">cad_clinical</span><span class="op">$</span><span class="va">hdl</span><span class="op">)</span></code></pre></div>
<p>Now that we have the data processed, we can fit a model.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">cad_lite_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plmm.html">plmm</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">cad_lite</span><span class="op">$</span><span class="va">genotypes</span>, y <span class="op">=</span> <span class="va">cad_clinical</span><span class="op">$</span><span class="va">hdl_impute</span>,
                     trace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co"># Passed all checks. Beginning standardization + rotation.</span>
<span class="co"># Standardization + rotation complete. Beginning model fitting.</span>
<span class="co"># Fitting model with lambda #1</span>
<span class="co"># Fitting model with lambda #2</span>
<span class="co"># Fitting model with lambda #3</span>
<span class="co"># Fitting model with lambda #4</span>
<span class="co"># Fitting model with lambda #5</span>
<span class="co"># Fitting model with lambda #6</span>
<span class="co"># Fitting model with lambda #7</span>
<span class="co"># Fitting model with lambda #8</span>
<span class="co"># Fitting model with lambda #9</span>
<span class="co"># Fitting model with lambda #10</span>
<span class="co"># Fitting model with lambda #11</span>
<span class="co"># Fitting model with lambda #12</span>
<span class="co"># Fitting model with lambda #13</span>
<span class="co"># Fitting model with lambda #14</span>
<span class="co"># Fitting model with lambda #15</span>
<span class="co"># Fitting model with lambda #16</span>
<span class="co"># Fitting model with lambda #17</span>
<span class="co"># Fitting model with lambda #18</span>
<span class="co"># Fitting model with lambda #19</span>
<span class="co"># Fitting model with lambda #20</span>
<span class="co"># Fitting model with lambda #21</span>
<span class="co"># Fitting model with lambda #22</span>
<span class="co"># Fitting model with lambda #23</span>
<span class="co"># Fitting model with lambda #24</span>
<span class="co"># Fitting model with lambda #25</span>
<span class="co"># Fitting model with lambda #26</span>
<span class="co"># Fitting model with lambda #27</span>
<span class="co"># Fitting model with lambda #28</span>
<span class="co"># Fitting model with lambda #29</span>
<span class="co"># Fitting model with lambda #30</span>
<span class="co"># Fitting model with lambda #31</span>
<span class="co"># Fitting model with lambda #32</span>
<span class="co"># Fitting model with lambda #33</span>
<span class="co"># Fitting model with lambda #34</span>
<span class="co"># Fitting model with lambda #35</span>
<span class="co"># Fitting model with lambda #36</span>
<span class="co"># Fitting model with lambda #37</span>
<span class="co"># Fitting model with lambda #38</span>
<span class="co"># Fitting model with lambda #39</span>
<span class="co"># Fitting model with lambda #40</span>
<span class="co"># Fitting model with lambda #41</span>
<span class="co"># Fitting model with lambda #42</span>
<span class="co"># Fitting model with lambda #43</span>
<span class="co"># Fitting model with lambda #44</span>
<span class="co"># Fitting model with lambda #45</span>
<span class="co"># Fitting model with lambda #46</span>
<span class="co"># Fitting model with lambda #47</span>
<span class="co"># Fitting model with lambda #48</span>
<span class="co"># Fitting model with lambda #49</span>
<span class="co"># Fitting model with lambda #50</span>
<span class="co"># Fitting model with lambda #51</span>
<span class="co"># Fitting model with lambda #52</span>
<span class="co"># Fitting model with lambda #53</span>
<span class="co"># Fitting model with lambda #54</span>
<span class="co"># Fitting model with lambda #55</span>
<span class="co"># Fitting model with lambda #56</span>
<span class="co"># Fitting model with lambda #57</span>
<span class="co"># Fitting model with lambda #58</span>
<span class="co"># Fitting model with lambda #59</span>
<span class="co"># Fitting model with lambda #60</span>
<span class="co"># Fitting model with lambda #61</span>
<span class="co"># Fitting model with lambda #62</span>
<span class="co"># Fitting model with lambda #63</span>
<span class="co"># Fitting model with lambda #64</span>
<span class="co"># Fitting model with lambda #65</span>
<span class="co"># Fitting model with lambda #66</span>
<span class="co"># Fitting model with lambda #67</span>
<span class="co"># Fitting model with lambda #68</span>
<span class="co"># Fitting model with lambda #69</span>
<span class="co"># Fitting model with lambda #70</span>
<span class="co"># Fitting model with lambda #71</span>
<span class="co"># Fitting model with lambda #72</span>
<span class="co"># Fitting model with lambda #73</span>
<span class="co"># Fitting model with lambda #74</span>
<span class="co"># Fitting model with lambda #75</span>
<span class="co"># Fitting model with lambda #76</span>
<span class="co"># Fitting model with lambda #77</span>
<span class="co"># Fitting model with lambda #78</span>
<span class="co"># Fitting model with lambda #79</span>
<span class="co"># Fitting model with lambda #80</span>
<span class="co"># Fitting model with lambda #81</span>
<span class="co"># Fitting model with lambda #82</span>
<span class="co"># Fitting model with lambda #83</span>
<span class="co"># Fitting model with lambda #84</span>
<span class="co"># Fitting model with lambda #85</span>
<span class="co"># Fitting model with lambda #86</span>
<span class="co"># Fitting model with lambda #87</span>
<span class="co"># Fitting model with lambda #88</span>
<span class="co"># Fitting model with lambda #89</span>
<span class="co"># Fitting model with lambda #90</span>
<span class="co"># Fitting model with lambda #91</span>
<span class="co"># Fitting model with lambda #92</span>
<span class="co"># Fitting model with lambda #93</span>
<span class="co"># Fitting model with lambda #94</span>
<span class="co"># Fitting model with lambda #95</span>
<span class="co"># Fitting model with lambda #96</span>
<span class="co"># Fitting model with lambda #97</span>
<span class="co"># Fitting model with lambda #98</span>
<span class="co"># Fitting model with lambda #99</span>
<span class="co"># Fitting model with lambda #100</span>
<span class="co"># Beta values are estimated -- almost done!</span>
<span class="co"># Warning in plmm(X = cad_lite$genotypes, y = cad_clinical$hdl_impute, trace = TRUE): Due to the large size of SUX (&gt;100 Mb), returnX has been turned off.</span>
<span class="co"># To turn this message off, explicitly specify returnX=TRUE or returnX=FALSE).</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">cad_lite_fit</span><span class="op">)</span>
<span class="co">#  [1] "beta_vals"      "eta"            "lambda"         "penalty"       </span>
<span class="co">#  [5] "gamma"          "alpha"          "convex.min"     "loss"          </span>
<span class="co">#  [9] "penalty.factor" "n"              "ns_idx"         "iter"          </span>
<span class="co"># [13] "converged"</span></code></pre></div>
<p>Notice that the returned <code>plmm</code> object does not include an
<span class="math inline">\(X\)</span> matrix; as noted by the warning,
this matrix is not returned due to its large size.</p>
<p>The returned <code>beta_vals</code> item is a matrix whose rows are
<span class="math inline">\(\beta\)</span> coefficients and whose
columns represent values of the penalization parameter <span class="math inline">\(\lambda\)</span>. By default, <code>plmm</code>
fits 100 values of <span class="math inline">\(\lambda\)</span> (see the
<code>setup_lambda</code> function for details).</p>
<p>We can summarize this fit at the 25th <span class="math inline">\(\lambda\)</span> value:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">cad_lite_fit</span>, lambda <span class="op">=</span> <span class="va">cad_lite_fit</span><span class="op">$</span><span class="va">lambda</span><span class="op">[</span><span class="fl">25</span><span class="op">]</span><span class="op">)</span>
<span class="co"># MCP-penalized regression model with n=1401, p=42118 at lambda=0.7809</span>
<span class="co"># -------------------------------------------------</span>
<span class="co"># The model converged </span>
<span class="co"># -------------------------------------------------</span>
<span class="co"># # of non-zero coefficients:  151 </span>
<span class="co"># Number of constant features (features without variation):  40609 </span>
<span class="co"># -------------------------------------------------</span></code></pre></div>
<p>Notice that a large number of these SNPs are constant features – that
is, SNPs whose values do not vary among the members of this population.
For such features, a value of <span class="math inline">\(\beta=0\)</span> is returned for all values of
<span class="math inline">\(\lambda\)</span>.</p>
<p>In order to make this model run in a more reasonable amount of time
on my laptop (which is a 2015 MacBook Pro), I am going to re-run this
model with an additional argument <span class="math inline">\(k\)</span>. If <span class="math inline">\(k\)</span> is specified and the package
<code>RSpectra</code> is installed, the singular value decomposition
algorithm is <code>RSpectra::svds(k, ...)</code> – this will be more
efficient.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">cad_lite_fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plmm.html">plmm</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">cad_lite</span><span class="op">$</span><span class="va">genotypes</span>, y <span class="op">=</span> <span class="va">cad_clinical</span><span class="op">$</span><span class="va">hdl_impute</span>, k <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">cad_lite_fit2</span><span class="op">)</span>
<span class="co">#  [1] "beta_vals"      "eta"            "lambda"         "penalty"       </span>
<span class="co">#  [5] "gamma"          "alpha"          "convex.min"     "loss"          </span>
<span class="co">#  [9] "penalty.factor" "n"              "ns_idx"         "iter"          </span>
<span class="co"># [13] "converged"      "X"              "y"              "std_X"         </span>
<span class="co"># [17] "U"              "S"              "SUX"            "SUy"</span></code></pre></div>
<p>Notice that <code>cad_lite_fit2</code> object <em>does</em> include a
<span class="math inline">\(X\)</span> matrix – the use of <span class="math inline">\(k\)</span> has reduced the returned matrix to a
size &lt; 100 Mb. Let’s summarize this new fit:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">cad_lite_fit2</span>, lambda <span class="op">=</span> <span class="va">cad_lite_fit2</span><span class="op">$</span><span class="va">lambda</span><span class="op">[</span><span class="fl">25</span><span class="op">]</span><span class="op">)</span>
<span class="co"># MCP-penalized regression model with n=1401, p=42118 at lambda=6.6468</span>
<span class="co"># -------------------------------------------------</span>
<span class="co"># The model converged </span>
<span class="co"># -------------------------------------------------</span>
<span class="co"># # of non-zero coefficients:  1 </span>
<span class="co"># Number of constant features (features without variation):  42116 </span>
<span class="co"># -------------------------------------------------</span></code></pre></div>
<p>TODO: examine why there is only one nonzero <span class="math inline">\(\beta\)</span> value returned in the second
summary call.</p>
</div>
<div class="section level2">
<h2 id="cross-validation">Cross validation<a class="anchor" aria-label="anchor" href="#cross-validation"></a>
</h2>
<p>To select a <span class="math inline">\(\lambda\)</span> value, we
often use cross validation. Below is an example of using
<code>cv.plmm</code> to select a <span class="math inline">\(\lambda\)</span> that minimizes cross-validation
error:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># FIXME: fix the warning issue </span>
<span class="va">admix_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.plmm.html">cv.plmm</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">admix</span><span class="op">$</span><span class="va">X</span>, y <span class="op">=</span> <span class="va">admix</span><span class="op">$</span><span class="va">y</span>, K <span class="op">=</span> <span class="fu"><a href="../reference/relatedness_mat.html">relatedness_mat</a></span><span class="op">(</span><span class="va">admix</span><span class="op">$</span><span class="va">X</span><span class="op">)</span><span class="op">)</span>


<span class="va">admix_cv_s</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/summary.cv.plmm.html">summary.cv.plmm</a></span><span class="op">(</span><span class="va">admix_cv</span>, lambda <span class="op">=</span> <span class="st">'1se'</span><span class="op">)</span>
<span class="fu"><a href="../reference/print.summary.cv.plmm.html">print.summary.cv.plmm</a></span><span class="op">(</span><span class="va">admix_cv_s</span><span class="op">)</span>
<span class="co"># MCP-penalized model with n=197</span>
<span class="co"># At minimum cross-validation error (lambda=0.0908):</span>
<span class="co"># -------------------------------------------------</span>
<span class="co">#   Nonzero coefficients: 26</span>
<span class="co">#   Cross-validation error (deviance): 2.42</span>
<span class="co">#   Scale estimate (sigma): 1.557</span></code></pre></div>
<p>TODO: figure out this error: ‘Warning in if (type == “blup”) { : the
condition has length &gt; 1 and only the first element will be used’</p>
<p>To see how this would work for our <code>cad_lite</code> data, we can
use the lines below:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># FIXME: this is taking several minutes -- need to come back here </span>
<span class="va">cad_lite_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.plmm.html">cv.plmm</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">cad_lite</span><span class="op">$</span><span class="va">genotypes</span>, 
                       y <span class="op">=</span> <span class="va">cad_clinical</span><span class="op">$</span><span class="va">hdl_impute</span>,
                       K <span class="op">=</span> <span class="fu"><a href="../reference/relatedness_mat.html">relatedness_mat</a></span><span class="op">(</span><span class="va">cad_lite</span><span class="op">$</span><span class="va">genotypes</span><span class="op">)</span>,
                       trace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>

<span class="fu"><a href="../reference/print.summary.cv.plmm.html">print.summary.cv.plmm</a></span><span class="op">(</span><span class="fu"><a href="../reference/summary.cv.plmm.html">summary.cv.plmm</a></span><span class="op">(</span><span class="va">cad_lite_cv</span>, lambda <span class="op">=</span> <span class="st">"1se"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="plots">Plots<a class="anchor" aria-label="anchor" href="#plots"></a>
</h2>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">admix_fit</span><span class="op">)</span></code></pre></div>
<p><img src="getting_started_files/figure-html/admix_plots-1.png" width="700"></p>
</div>
<div class="section level2">
<h2 id="predicted-values">Predicted values<a class="anchor" aria-label="anchor" href="#predicted-values"></a>
</h2>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># simulate new data </span>
<span class="va">admix_newX</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sim_ps_x.html">sim_ps_x</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">admix</span><span class="op">$</span><span class="va">X</span><span class="op">)</span>, nJ <span class="op">=</span> <span class="fl">4</span>, p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">admix</span><span class="op">$</span><span class="va">X</span><span class="op">)</span>,
  structureX <span class="op">=</span> <span class="st">"independent"</span>, inbr <span class="op">=</span> <span class="st">"heterogeneous"</span>, standardizeX <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="co"># make predictions for a select number of lambda values</span>
<span class="va">admix_pred1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">admix_fit</span>, newX <span class="op">=</span> <span class="va">admix_newX</span>, type <span class="op">=</span> <span class="st">"response"</span>, idx<span class="op">=</span><span class="fl">98</span><span class="op">)</span>

<span class="co"># make prediction using blup </span>
<span class="va">admix_pred2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">admix_fit</span>, newX <span class="op">=</span> <span class="va">admix_newX</span>, type <span class="op">=</span> <span class="st">"blup"</span>, idx<span class="op">=</span><span class="fl">98</span><span class="op">)</span>
<span class="co"># Warning in predict.plmm(object = admix_fit, newX = admix_newX, type = "blup", :</span>
<span class="co"># The BLUP option is under development. Rely on these estimates at your own risk.</span>

<span class="co"># compare y predictions </span>
<span class="va">admix_compare_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">admix</span><span class="op">$</span><span class="va">y</span>, yhat_response <span class="op">=</span> <span class="va">admix_pred1</span>, yhat_blup <span class="op">=</span> <span class="va">admix_pred2</span><span class="op">)</span>

<span class="op">(</span><span class="va">admix_compare_y</span><span class="op">)</span>
<span class="co">#                y yhat_response    X0.00039</span>
<span class="co"># 1    2.821334577   -1.64162741 -1.64161707</span>
<span class="co"># 2    1.333134654   -1.29908533 -1.29907935</span>
<span class="co"># 3    2.129287735   -0.89341581 -0.89341717</span>
<span class="co"># 4    3.715064987   -1.25554130 -1.25554646</span>
<span class="co"># 5    1.723542469   -3.65745455 -3.65745143</span>
<span class="co"># 6    0.734938765    0.31008624  0.31008930</span>
<span class="co"># 7    1.313147148   -1.67206875 -1.67206476</span>
<span class="co"># 8    0.816964293   -2.13692300 -2.13692452</span>
<span class="co"># 9    3.224081797   -1.15945580 -1.15945142</span>
<span class="co"># 10   1.622440090   -3.72069227 -3.72069235</span>
<span class="co"># 11   2.410872461   -2.64024382 -2.64023635</span>
<span class="co"># 12   1.373308979   -3.74670523 -3.74670645</span>
<span class="co"># 13   0.716886138   -6.65041079 -6.65040821</span>
<span class="co"># 14   3.786913137   -1.13621970 -1.13621712</span>
<span class="co"># 15   1.023103003   -1.86272607 -1.86273022</span>
<span class="co"># 16  -0.703990894   -1.04422966 -1.04422550</span>
<span class="co"># 17   2.701355902   -3.40188342 -3.40188457</span>
<span class="co"># 18   0.789834855   -2.30182588 -2.30183012</span>
<span class="co"># 19   0.942277304   -5.11711494 -5.11711998</span>
<span class="co"># 20   1.054752358   -0.68679301 -0.68679211</span>
<span class="co"># 21   0.984096562   -4.42632136 -4.42632435</span>
<span class="co"># 22   1.271108771   -2.74136718 -2.74136376</span>
<span class="co"># 23   0.637586995   -6.26696448 -6.26696322</span>
<span class="co"># 24   0.333508709   -1.64827740 -1.64827936</span>
<span class="co"># 25   2.847888055   -3.83658399 -3.83658683</span>
<span class="co"># 26   2.153373118   -2.33211814 -2.33211717</span>
<span class="co"># 27   0.124489326   -2.79586457 -2.79586342</span>
<span class="co"># 28   2.516441184   -5.88925227 -5.88925014</span>
<span class="co"># 29   2.426464221    0.30909806  0.30909710</span>
<span class="co"># 30   1.704928517   -2.27018520 -2.27018718</span>
<span class="co"># 31   2.895125661   -0.73070156 -0.73069555</span>
<span class="co"># 32   2.878133488   -1.73147121 -1.73146740</span>
<span class="co"># 33   2.084207344    2.01165026  2.01165739</span>
<span class="co"># 34   2.688640254   -6.01912442 -6.01912500</span>
<span class="co"># 35   1.816543916   -1.97532343 -1.97531637</span>
<span class="co"># 36   1.200714552   -1.49255239 -1.49254603</span>
<span class="co"># 37   0.956663599   -2.90348145 -2.90347894</span>
<span class="co"># 38   1.619528999    1.19619584  1.19619758</span>
<span class="co"># 39   1.315394031   -3.13808463 -3.13809274</span>
<span class="co"># 40   1.054708985   -3.43688130 -3.43687947</span>
<span class="co"># 41  -0.740143826   -2.39816133 -2.39816717</span>
<span class="co"># 42   3.441683238   -3.38420816 -3.38420939</span>
<span class="co"># 43   3.218063008   -0.44484370 -0.44484220</span>
<span class="co"># 44   0.876891417   -0.76416825 -0.76416966</span>
<span class="co"># 45   0.859741427   -0.97069251 -0.97068407</span>
<span class="co"># 46   1.533344646   -0.95089262 -0.95090277</span>
<span class="co"># 47   2.790066128   -3.38136995 -3.38137991</span>
<span class="co"># 48  -0.820742804   -1.54758570 -1.54758671</span>
<span class="co"># 49  -0.484055223   -0.80984045 -0.80983954</span>
<span class="co"># 50  -0.018445745   -1.82255710 -1.82256264</span>
<span class="co"># 51  -0.780244195    0.16636178  0.16636095</span>
<span class="co"># 52  -0.106145191    1.19125054  1.19125845</span>
<span class="co"># 53  -0.215669976    0.34378760  0.34378645</span>
<span class="co"># 54   1.526571615    2.77436016  2.77435518</span>
<span class="co"># 55  -1.528550784   -0.86429554 -0.86429474</span>
<span class="co"># 56   0.584613750   -3.52384730 -3.52384355</span>
<span class="co"># 57   0.144056264   -4.54509521 -4.54508703</span>
<span class="co"># 58   0.236143589   -0.54413439 -0.54413968</span>
<span class="co"># 59  -0.357734255   -1.69203098 -1.69202277</span>
<span class="co"># 60  -1.239697190   -0.92125221 -0.92125937</span>
<span class="co"># 61  -0.333207384   -2.92884965 -2.92885834</span>
<span class="co"># 62  -1.008474373    2.53565467  2.53565344</span>
<span class="co"># 63  -1.799063954   -1.21105938 -1.21105739</span>
<span class="co"># 64  -0.433845096    0.96722087  0.96721952</span>
<span class="co"># 65  -0.279062949   -2.26786948 -2.26786390</span>
<span class="co"># 66  -1.401541228   -0.09615146 -0.09614916</span>
<span class="co"># 67   0.184893731   -2.83418208 -2.83418333</span>
<span class="co"># 68   1.322811958   -2.32059092 -2.32058446</span>
<span class="co"># 69  -1.955677631   -3.48743476 -3.48742927</span>
<span class="co"># 70  -3.036441603   -0.61729810 -0.61728986</span>
<span class="co"># 71   1.015839535   -2.12958804 -2.12958591</span>
<span class="co"># 72  -1.446574500   -3.55198089 -3.55197779</span>
<span class="co"># 73  -0.688008616   -3.14238843 -3.14238750</span>
<span class="co"># 74   0.288197632   -4.28225127 -4.28225350</span>
<span class="co"># 75  -0.274671997   -2.54343443 -2.54344499</span>
<span class="co"># 76  -1.947990440   -2.55068556 -2.55068930</span>
<span class="co"># 77  -0.535868237   -4.35913723 -4.35913801</span>
<span class="co"># 78  -1.593436817   -4.69310249 -4.69309960</span>
<span class="co"># 79  -0.721508541   -2.65630703 -2.65629621</span>
<span class="co"># 80   0.395381411   -1.45765974 -1.45766330</span>
<span class="co"># 81  -1.845407507   -0.64701875 -0.64701765</span>
<span class="co"># 82   0.654477559   -2.77197359 -2.77196937</span>
<span class="co"># 83  -0.947759289   -4.22911722 -4.22911017</span>
<span class="co"># 84  -1.142965511   -2.01550484 -2.01551381</span>
<span class="co"># 85   0.359465276   -0.31132659 -0.31132799</span>
<span class="co"># 86  -1.029464974   -2.69828723 -2.69829828</span>
<span class="co"># 87  -1.063305323   -4.41498488 -4.41498581</span>
<span class="co"># 88   0.411433881   -0.22147859 -0.22147314</span>
<span class="co"># 89   0.266231129   -1.34898921 -1.34898956</span>
<span class="co"># 90  -0.916249505    0.17246927  0.17247072</span>
<span class="co"># 91   0.258933755   -3.63540625 -3.63540952</span>
<span class="co"># 92  -1.355178803   -1.90339556 -1.90339624</span>
<span class="co"># 93   0.623278711   -3.36238067 -3.36237653</span>
<span class="co"># 94  -1.327532314   -2.36538191 -2.36538611</span>
<span class="co"># 95   0.712585518   -3.13150855 -3.13150648</span>
<span class="co"># 96   0.805337899   -1.35780166 -1.35780459</span>
<span class="co"># 97  -1.700346824   -3.57434745 -3.57434689</span>
<span class="co"># 98  -4.016319890   -2.37203156 -2.37203330</span>
<span class="co"># 99  -4.427578281   -1.25144739 -1.25144956</span>
<span class="co"># 100 -2.733015281   -1.59427091 -1.59427617</span>
<span class="co"># 101 -3.226489858   -1.31065718 -1.31065881</span>
<span class="co"># 102 -4.074815327   -5.84213975 -5.84214274</span>
<span class="co"># 103 -4.688992305   -1.46835127 -1.46834273</span>
<span class="co"># 104 -4.509674189   -3.64618706 -3.64618649</span>
<span class="co"># 105 -4.512177197   -0.72545013 -0.72544257</span>
<span class="co"># 106 -5.385113654    1.82983359  1.82983309</span>
<span class="co"># 107 -4.107499248   -2.16272986 -2.16273264</span>
<span class="co"># 108 -2.808276118   -1.99470776 -1.99470908</span>
<span class="co"># 109 -3.575346963   -1.27392118 -1.27392477</span>
<span class="co"># 110 -3.129409415   -2.16016218 -2.16016100</span>
<span class="co"># 111 -4.617882708   -1.20094139 -1.20094635</span>
<span class="co"># 112 -3.792935703   -1.42306761 -1.42306533</span>
<span class="co"># 113 -3.217966533   -4.26734454 -4.26734116</span>
<span class="co"># 114 -2.688745628    0.12435754  0.12435134</span>
<span class="co"># 115 -3.631697543   -1.59892973 -1.59892337</span>
<span class="co"># 116 -4.378079746   -3.56193311 -3.56193183</span>
<span class="co"># 117 -4.576977073    0.47751665  0.47751191</span>
<span class="co"># 118 -4.751401518   -1.07123457 -1.07123741</span>
<span class="co"># 119 -2.882353403   -0.59111147 -0.59110947</span>
<span class="co"># 120 -3.937373604   -0.31029050 -0.31028870</span>
<span class="co"># 121 -4.227931181   -1.07759803 -1.07760009</span>
<span class="co"># 122 -3.983364919   -2.69695917 -2.69696115</span>
<span class="co"># 123 -2.620784459    1.05888306  1.05888363</span>
<span class="co"># 124 -3.651949902   -1.61545669 -1.61545588</span>
<span class="co"># 125 -4.239360902   -1.80667639 -1.80667536</span>
<span class="co"># 126 -2.911938140   -0.11858768 -0.11859654</span>
<span class="co"># 127 -5.416402089   -1.45162920 -1.45162783</span>
<span class="co"># 128 -4.546055561   -1.79082247 -1.79081700</span>
<span class="co"># 129 -1.545348131    1.75825714  1.75826463</span>
<span class="co"># 130 -2.528293927   -0.25925650 -0.25925543</span>
<span class="co"># 131 -4.433514553    0.46920499  0.46921114</span>
<span class="co"># 132 -3.422496832   -2.72075879 -2.72076359</span>
<span class="co"># 133 -5.790620959   -1.83856838 -1.83856082</span>
<span class="co"># 134 -2.606036524   -3.07393257 -3.07392910</span>
<span class="co"># 135 -5.925286536   -1.47430221 -1.47430238</span>
<span class="co"># 136 -2.260052489   -1.25169183 -1.25169088</span>
<span class="co"># 137 -2.565643906   -3.01254508 -3.01254730</span>
<span class="co"># 138 -4.443893161   -1.69277626 -1.69277057</span>
<span class="co"># 139 -3.762862129   -1.66237147 -1.66236515</span>
<span class="co"># 140 -3.262197489   -3.00288361 -3.00287975</span>
<span class="co"># 141 -5.299416886   -1.60763031 -1.60763493</span>
<span class="co"># 142 -4.514667654   -3.30600004 -3.30599472</span>
<span class="co"># 143 -5.328808901   -0.92224530 -0.92224228</span>
<span class="co"># 144 -4.985451977   -1.83482524 -1.83482987</span>
<span class="co"># 145 -5.189028312   -1.20245705 -1.20245588</span>
<span class="co"># 146 -2.301982217    0.35343173  0.35343450</span>
<span class="co"># 147 -1.627163787   -1.16293451 -1.16293577</span>
<span class="co"># 148  0.712969524    0.26618046  0.26616878</span>
<span class="co"># 149  2.787738847   -3.84625777 -3.84625588</span>
<span class="co"># 150  2.031668504   -1.97864730 -1.97865732</span>
<span class="co"># 151  1.594828842   -3.00486752 -3.00487095</span>
<span class="co"># 152  0.264350664   -2.72209473 -2.72208925</span>
<span class="co"># 153  1.880547393    0.66610891  0.66610587</span>
<span class="co"># 154  1.002432948   -4.29541211 -4.29541312</span>
<span class="co"># 155  2.562989533    1.05975412  1.05974531</span>
<span class="co"># 156  1.627561244   -1.44744719 -1.44745331</span>
<span class="co"># 157  2.239599649   -0.62766476 -0.62766124</span>
<span class="co"># 158  1.635520152   -1.64723217 -1.64723551</span>
<span class="co"># 159  3.052711466   -3.43114638 -3.43114827</span>
<span class="co"># 160  0.950822993   -0.06229771 -0.06229748</span>
<span class="co"># 161  0.002471018   -1.84726375 -1.84725758</span>
<span class="co"># 162  5.251140945   -2.68143324 -2.68143439</span>
<span class="co"># 163  1.583142412   -0.38301589 -0.38302757</span>
<span class="co"># 164  1.560853854   -0.79436628 -0.79436725</span>
<span class="co"># 165  1.909296947   -2.22496414 -2.22496462</span>
<span class="co"># 166  1.516219374   -3.49140352 -3.49141253</span>
<span class="co"># 167  2.526963054   -3.68815947 -3.68815723</span>
<span class="co"># 168  2.368964527    0.91109493  0.91109884</span>
<span class="co"># 169  1.784619492    0.58271520  0.58271232</span>
<span class="co"># 170  2.065293034    0.09614906  0.09614476</span>
<span class="co"># 171  1.965932746   -3.11602368 -3.11602851</span>
<span class="co"># 172  2.663805434    0.35578470  0.35578987</span>
<span class="co"># 173  1.258663904   -4.36774808 -4.36774876</span>
<span class="co"># 174  0.176731006   -1.01724149 -1.01724157</span>
<span class="co"># 175  2.037788399    0.51447239  0.51446065</span>
<span class="co"># 176  1.573107012    1.92652367  1.92653112</span>
<span class="co"># 177  1.699149742    1.62563002  1.62562843</span>
<span class="co"># 178  1.551735677   -1.21657943 -1.21658388</span>
<span class="co"># 179  0.936673866    0.07908000  0.07906703</span>
<span class="co"># 180  3.263185176   -0.87181517 -0.87180799</span>
<span class="co"># 181  1.650349612   -1.92862160 -1.92862240</span>
<span class="co"># 182  1.134487137   -1.39451087 -1.39450867</span>
<span class="co"># 183  1.763720431   -4.03581773 -4.03581604</span>
<span class="co"># 184  1.065450368   -0.07742859 -0.07742745</span>
<span class="co"># 185  2.372546552   -1.98428770 -1.98428417</span>
<span class="co"># 186  2.084737292    0.33728024  0.33728439</span>
<span class="co"># 187  2.754053785   -3.71412505 -3.71412700</span>
<span class="co"># 188  0.763334245   -3.94914469 -3.94913899</span>
<span class="co"># 189  2.214445310    0.66624287  0.66624404</span>
<span class="co"># 190  1.675314089   -3.79927428 -3.79926987</span>
<span class="co"># 191  2.094583528   -3.21767138 -3.21767614</span>
<span class="co"># 192  1.104636642   -2.39435299 -2.39436140</span>
<span class="co"># 193  0.689198467   -2.38189986 -2.38190243</span>
<span class="co"># 194  3.269940657   -3.16575700 -3.16575977</span>
<span class="co"># 195  2.600708824    0.26579760  0.26579383</span>
<span class="co"># 196  0.748728638   -3.27688760 -3.27688457</span>
<span class="co"># 197  0.651460346   -1.49672456 -1.49672415</span>

<span class="co"># FIXME: why are my predictions so off? Something is wrong in predict.plmm()....</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># make predictions when X is bigger</span>
<span class="va">cad_X</span> <span class="op">&lt;-</span> <span class="va">cad_lite</span><span class="op">$</span><span class="va">genotypes</span>
<span class="va">cad_y</span> <span class="op">&lt;-</span> <span class="va">cad_clinical</span><span class="op">$</span><span class="va">hdl_impute</span>

<span class="va">cad_lite_newX</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sim_ps_x.html">sim_ps_x</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">cad_X</span><span class="op">)</span>, nJ <span class="op">=</span> <span class="fl">4</span>, p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">cad_X</span><span class="op">)</span>,
  structureX <span class="op">=</span> <span class="st">"independent"</span>, inbr <span class="op">=</span> <span class="st">"heterogeneous"</span>, standardizeX <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="va">cad_lite_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span>object <span class="op">=</span> <span class="va">cad_lite_fit</span>,
                         newX <span class="op">=</span> <span class="va">cad_lite_newX</span>,
                         type<span class="op">=</span><span class="st">'blup'</span>,
                         idx <span class="op">=</span> <span class="fl">95</span>,
                         <span class="co"># for BLUP prediction method, must supply X and y</span>
                         X <span class="op">=</span> <span class="va">cad_X</span>,
                         y <span class="op">=</span> <span class="va">cad_y</span><span class="op">)</span>

<span class="co"># compare the observed and predicted values </span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">cad_y</span>, <span class="va">cad_lite_pred</span><span class="op">)</span><span class="op">)</span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Anna C. Reisetter, Patrick J. Breheny.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.4.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
